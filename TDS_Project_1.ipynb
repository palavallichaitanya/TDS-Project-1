{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0A6OWMzb5BmY"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "class GitHubScraper:\n",
        "    def _init_(self, token: str):\n",
        "        \"\"\"\n",
        "        Initialize the GitHub scraper with your API token.\n",
        "\n",
        "        Args:\n",
        "            token (str): GitHub Personal Access Token\n",
        "        \"\"\"\n",
        "        self.headers = {\n",
        "            'Authorization': f'token {token}',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        }\n",
        "        self.base_url = 'https://api.github.com'\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(_name_)\n",
        "\n",
        "    def _make_request(self, url: str, params: dict = None) -> Dict:\n",
        "        \"\"\"\n",
        "        Make a request to the GitHub API with rate limit handling.\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
        "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
        "                self.logger.warning(f\"Rate limit hit. Sleeping for {sleep_time} seconds\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                self.logger.error(f\"Error {response.status_code}: {response.text}\")\n",
        "                response.raise_for_status()\n",
        "\n",
        "    def clean_company_name(self, company: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean up company names according to specifications.\n",
        "        \"\"\"\n",
        "        if not company:\n",
        "            return \"\"\n",
        "\n",
        "        # Strip whitespace and @ symbol\n",
        "        cleaned = company.strip().lstrip('@')\n",
        "\n",
        "        # Convert to uppercase\n",
        "        return cleaned.upper()\n",
        "\n",
        "    def search_users(self, location: str, min_followers: int) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Search for GitHub users in a specific location with minimum followers.\n",
        "        \"\"\"\n",
        "        users = []\n",
        "        page = 1\n",
        "\n",
        "        while True:\n",
        "            self.logger.info(f\"Fetching users page {page}\")\n",
        "\n",
        "            query = f\"location:{location} followers:>={min_followers}\"\n",
        "            params = {\n",
        "                'q': query,\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/search/users\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response['items']:\n",
        "                break\n",
        "\n",
        "            for user in response['items']:\n",
        "                user_data = self._make_request(user['url'])\n",
        "\n",
        "                # Extract only the required fields with exact matching names\n",
        "                cleaned_data = {\n",
        "                    'login': user_data['login'],\n",
        "                    'name': user_data['name'] if user_data['name'] else \"\",\n",
        "                    'company': self.clean_company_name(user_data.get('company')),\n",
        "                    'location': user_data['location'] if user_data['location'] else \"\",\n",
        "                    'email': user_data['email'] if user_data['email'] else \"\",\n",
        "                    'hireable': user_data['hireable'] if user_data['hireable'] is not None else False,\n",
        "                    'bio': user_data['bio'] if user_data['bio'] else \"\",\n",
        "                    'public_repos': user_data['public_repos'],\n",
        "                    'followers': user_data['followers'],\n",
        "                    'following': user_data['following'],\n",
        "                    'created_at': user_data['created_at']\n",
        "                }\n",
        "\n",
        "                users.append(cleaned_data)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return users\n",
        "\n",
        "    def get_user_repositories(self, username: str, max_repos: int = 500) -> List[Dict]:\n",
        "        \"\"\"\n",
        "        Get repositories for a specific user.\n",
        "        \"\"\"\n",
        "        repos = []\n",
        "        page = 1\n",
        "\n",
        "        while len(repos) < max_repos:\n",
        "            self.logger.info(f\"Fetching repositories for {username}, page {page}\")\n",
        "\n",
        "            params = {\n",
        "                'sort': 'pushed',\n",
        "                'direction': 'desc',\n",
        "                'per_page': 100,\n",
        "                'page': page\n",
        "            }\n",
        "\n",
        "            url = f\"{self.base_url}/users/{username}/repos\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            for repo in response:\n",
        "                # Extract only the required fields with exact matching names\n",
        "                repo_data = {\n",
        "                    'login': username,  # Adding owner's login as required\n",
        "                    'full_name': repo['full_name'],\n",
        "                    'created_at': repo['created_at'],\n",
        "                    'stargazers_count': repo['stargazers_count'],\n",
        "                    'watchers_count': repo['watchers_count'],\n",
        "                    'language': repo['language'] if repo['language'] else \"\",\n",
        "                    'has_projects': repo['has_projects'],\n",
        "                    'has_wiki': repo['has_wiki'],\n",
        "                    'license_name': repo['license']['key'] if repo.get('license') else \"\"\n",
        "                }\n",
        "\n",
        "                repos.append(repo_data)\n",
        "\n",
        "            if len(response) < 100:\n",
        "                break\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return repos[:max_repos]\n",
        "\n",
        "def main():\n",
        "    # Get GitHub token\n",
        "    token = input(\"Enter your GitHub token: \").strip()\n",
        "    if not token:\n",
        "        print(\"Token is required. Exiting...\")\n",
        "        return\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = GitHubScraper(token)\n",
        "\n",
        "    # Search for users in Delhi with >100 followers\n",
        "    users = scraper.search_users(location='Austin', min_followers=100)\n",
        "\n",
        "    # Save users to CSV\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Get repositories for each user\n",
        "    all_repos = []\n",
        "    for user in users:\n",
        "        repos = scraper.get_user_repositories(user['login'])\n",
        "        all_repos.extend(repos)\n",
        "\n",
        "    # Save repositories to CSV\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "    print(f\"Scraped {len(users)} users and {len(all_repos)} repositories\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#users.csv\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "# Replace with your personal access token\n",
        "GITHUB_TOKEN = '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'\n",
        "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "BASE_URL = 'https://api.github.com'\n",
        "\n",
        "def get_users_in_Austin():\n",
        "    users = []\n",
        "    page = 1\n",
        "\n",
        "    while True:\n",
        "        response = requests.get(f'{BASE_URL}/search/users',\n",
        "                                headers=HEADERS,\n",
        "                                params={'q': 'location:Austin followers:>100', 'page': page})\n",
        "        data = response.json()\n",
        "\n",
        "        if 'items' not in data or not data['items']:\n",
        "            break\n",
        "\n",
        "        for user in data['items']:\n",
        "            users.append(user['login'])\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return users\n",
        "\n",
        "def get_user_details(username):\n",
        "    response = requests.get(f'{BASE_URL}/users/{username}', headers=HEADERS)\n",
        "    return response.json()\n",
        "\n",
        "def clean_company(company):\n",
        "    if company:\n",
        "        return company.strip().lstrip('@').upper()\n",
        "    return None\n",
        "\n",
        "def main():\n",
        "    users = get_users_in_Austin()\n",
        "    user_details = []\n",
        "\n",
        "    for user in users:\n",
        "        details = get_user_details(user)\n",
        "        user_details.append({\n",
        "            'login': details.get('login'),\n",
        "            'name': details.get('name'),\n",
        "            'company': clean_company(details.get('company')),\n",
        "            'location': details.get('location'),\n",
        "            'email': details.get('email'),\n",
        "            'hireable': details.get('hireable'),\n",
        "            'bio': details.get('bio'),\n",
        "            'public_repos': details.get('public_repos'),\n",
        "            'followers': details.get('followers'),\n",
        "            'following': details.get('following'),\n",
        "            'created_at': details.get('created_at'),\n",
        "        })\n",
        "\n",
        "    # Write to CSV\n",
        "    with open('users.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['login', 'name', 'company', 'location', 'email',\n",
        "                      'hireable', 'bio', 'public_repos', 'followers',\n",
        "                      'following', 'created_at']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for user in user_details:\n",
        "            writer.writerow(user)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "w330DVgjUsCD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#more cleaned users.csv\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Clean the company names\n",
        "users_df['company'] = users_df['company'].str.strip()  # Trim whitespace\n",
        "users_df['company'] = users_df['company'].str.lstrip('@')  # Strip leading '@'\n",
        "users_df['company'] = users_df['company'].str.upper()  # Convert to uppercase\n",
        "\n",
        "# Save the cleaned DataFrame back to users.csv\n",
        "users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "print(\"Company names cleaned and saved to users.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSeaZU1yXCDr",
        "outputId": "7fd38d84-c03d-448f-8271-732f688c7572"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Company names cleaned and saved to users.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#repositories.csv\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "# Replace with your personal access token\n",
        "GITHUB_TOKEN = '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'\n",
        "HEADERS = {'Authorization': f'token {GITHUB_TOKEN}'}\n",
        "BASE_URL = 'https://api.github.com'\n",
        "\n",
        "def read_users_from_csv(file_path):\n",
        "    users = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            users.append(row['login'])\n",
        "    return users\n",
        "\n",
        "def get_repositories(username):\n",
        "    repos = []\n",
        "    page = 1\n",
        "    while True:\n",
        "        response = requests.get(f'{BASE_URL}/users/{username}/repos',\n",
        "                                headers=HEADERS,\n",
        "                                params={'sort': 'pushed', 'direction': 'desc', 'per_page': 100, 'page': page})\n",
        "        data = response.json()\n",
        "\n",
        "        if not data or len(repos) >= 500:\n",
        "            break\n",
        "\n",
        "        for repo in data:\n",
        "            repos.append({\n",
        "                'full_name': repo['full_name'],\n",
        "                'created_at': repo['created_at'],\n",
        "                'stargazers_count': repo['stargazers_count'],\n",
        "                'watchers_count': repo['watchers_count'],\n",
        "                'language': repo['language'],\n",
        "                'has_projects': repo['has_projects'],\n",
        "                'has_wiki': repo['has_wiki'],\n",
        "                'license_name': repo['license']['key'] if repo.get('license') else None  # Safely fetch license key\n",
        "            })\n",
        "\n",
        "        page += 1\n",
        "\n",
        "    return repos[:500]  # Return up to 500 repos\n",
        "\n",
        "def main():\n",
        "    users = read_users_from_csv('users.csv')\n",
        "    all_repos = []\n",
        "\n",
        "    for user in users:\n",
        "        repos = get_repositories(user)\n",
        "        for repo in repos:\n",
        "            all_repos.append({\n",
        "                'login': user,\n",
        "                **repo\n",
        "            })\n",
        "\n",
        "    # Write to CSV\n",
        "    with open('repositories.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['login', 'full_name', 'created_at',\n",
        "                      'stargazers_count', 'watchers_count',\n",
        "                      'language', 'has_projects',\n",
        "                      'has_wiki', 'license_name']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for repo in all_repos:\n",
        "            writer.writerow(repo)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "CLgDkKJdX-jC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Q1\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Sort by followers and get top 5\n",
        "top_users = users_df.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Extract logins\n",
        "top_logins = top_users['login'].tolist()\n",
        "result = ', '.join(top_logins)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIjZ8kn9YrNO",
        "outputId": "f6bdb386-a68a-43a1-a4a1-8c9cfcb2d8f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getify, benawad, steveklabnik, cloudflare, jbogard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q2\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert created_at to datetime\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Sort by created_at and get the earliest 5 users\n",
        "earliest_users = users_df.sort_values(by='created_at').head(5)\n",
        "\n",
        "# Extract logins\n",
        "earliest_logins = earliest_users['login'].tolist()\n",
        "result = ', '.join(earliest_logins)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUTZCHifYwfE",
        "outputId": "2189af57-ddd4-4b93-a143-818f46f7503c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "jnewland, joshknowles, hassox, jicksta, dan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q3\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "repositories_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out missing license names\n",
        "repositories_df = repositories_df[repositories_df['license_name'].notna()]\n",
        "\n",
        "# Count occurrences of each license\n",
        "license_counts = repositories_df['license_name'].value_counts()\n",
        "\n",
        "# Get the top 3 licenses\n",
        "top_licenses = license_counts.head(3).index.tolist()\n",
        "\n",
        "# Join the license names in order\n",
        "result = ', '.join(top_licenses)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3iKR40XYzea",
        "outputId": "8c79f1c1-f243-435e-a8ed-e7594d0007c7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mit, apache-2.0, other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q4\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Count occurrences of each company\n",
        "company_counts = users_df['company'].value_counts()\n",
        "\n",
        "# Get the company with the highest count\n",
        "most_common_company = company_counts.idxmax()\n",
        "most_common_count = company_counts.max()\n",
        "\n",
        "print(f\"The majority of developers work at: {most_common_company} with {most_common_count} developers.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSUb6tvNY2BM",
        "outputId": "52584ce6-5dcf-4121-da14-ee5e88c86d60"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The majority of developers work at: GOOGLE with 9 developers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q5\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "repositories_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Count occurrences of each programming language, ignoring missing values\n",
        "language_counts = repositories_df['language'].value_counts()\n",
        "\n",
        "# Get the most popular programming language\n",
        "most_popular_language = language_counts.idxmax()\n",
        "most_popular_count = language_counts.max()\n",
        "\n",
        "print(f\"The most popular programming language is: {most_popular_language} with {most_popular_count} repositories.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yreUfiq0Y4CW",
        "outputId": "887ab9e1-765e-4c00-f343-de5251c2e81b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most popular programming language is: JavaScript with 9006 repositories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q6\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "repositories_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert created_at to datetime and filter users who joined after 2020\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "recent_users = users_df[users_df['created_at'] > '2020-01-01']\n",
        "\n",
        "# Get the logins of recent users\n",
        "recent_user_logins = recent_users['login'].tolist()\n",
        "\n",
        "# Filter repositories by these users\n",
        "recent_repositories = repositories_df[repositories_df['login'].isin(recent_user_logins)]\n",
        "\n",
        "# Count occurrences of each programming language\n",
        "language_counts = recent_repositories['language'].value_counts()\n",
        "\n",
        "# Get the second most popular programming language\n",
        "second_most_popular_language = language_counts.nlargest(2).index[1]\n",
        "second_most_popular_count = language_counts.nlargest(2).values[1]\n",
        "\n",
        "print(f\"The second most popular programming language among users who joined after 2020 is: {second_most_popular_language} with {second_most_popular_count} repositories.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3CasPDDY6GA",
        "outputId": "8671001e-c0e6-408b-cfa3-ee6df513e0ea"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second most popular programming language among users who joined after 2020 is: HTML with 75 repositories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q7\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "repositories_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Group by programming language and calculate the average stars\n",
        "average_stars = repositories_df.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "# Identify the language with the highest average stars\n",
        "highest_average_language = average_stars.idxmax()\n",
        "highest_average_value = average_stars.max()\n",
        "\n",
        "print(f\"The programming language with the highest average number of stars per repository is: {highest_average_language} with an average of {highest_average_value:.2f} stars.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nYIrgFjY8Dq",
        "outputId": "7bfe4c75-e3ba-4199-c288-cefecea9b788"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The programming language with the highest average number of stars per repository is: Fennel with an average of 2446.00 stars.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q8\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate leader_strength\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Sort by leader_strength and get the top 5\n",
        "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "# Extract logins\n",
        "top_logins = top_leaders['login'].tolist()\n",
        "result = ', '.join(top_logins)\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfQcFmrVY916",
        "outputId": "9158eb1f-38a2-420f-aba5-6637716172d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "getify, cloudflare, benawad, oracle, ContinuumIO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q9\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the correlation between followers and public repositories\n",
        "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
        "\n",
        "print(f\"The correlation between the number of followers and the number of public repositories is: {correlation:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQf1LscmY_xs",
        "outputId": "5fbe4d46-e7fd-45b8-c3d0-1f5ba2b2a522"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The correlation between the number of followers and the number of public repositories is: 0.150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q10\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Define the independent variable (X) and dependent variable (Y)\n",
        "X = users_df['public_repos']\n",
        "Y = users_df['followers']\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Get the summary of the regression results\n",
        "summary = model.summary()\n",
        "\n",
        "# Extract the coefficient for public_repos\n",
        "additional_followers_per_repo = model.params['public_repos']\n",
        "\n",
        "print(f\"Regression Results:\\n{summary}\")\n",
        "print(f\"Estimated additional followers per additional public repository: {additional_followers_per_repo:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JI8KrU3JZBzD",
        "outputId": "5d5ca241-86aa-4392-95b8-b18fd2909a5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression Results:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              followers   R-squared:                       0.023\n",
            "Model:                            OLS   Adj. R-squared:                  0.021\n",
            "Method:                 Least Squares   F-statistic:                     10.85\n",
            "Date:                Thu, 31 Oct 2024   Prob (F-statistic):            0.00106\n",
            "Time:                        11:54:55   Log-Likelihood:                -4347.8\n",
            "No. Observations:                 471   AIC:                             8700.\n",
            "Df Residuals:                     469   BIC:                             8708.\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const          190.8116    158.342      1.205      0.229    -120.337     501.960\n",
            "public_repos     4.0890      1.241      3.294      0.001       1.650       6.528\n",
            "==============================================================================\n",
            "Omnibus:                      962.432   Durbin-Watson:                   0.334\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          1095499.518\n",
            "Skew:                          14.625   Prob(JB):                         0.00\n",
            "Kurtosis:                     237.448   Cond. No.                         177.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Estimated additional followers per additional public repository: 4.089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q11\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def analyze_repo_features(csv_file):\n",
        "\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    if df['has_projects'].dtype == 'object':\n",
        "        df['has_projects'] = df['has_projects'].map({'true': True, 'false': False})\n",
        "    if df['has_wiki'].dtype == 'object':\n",
        "        df['has_wiki'] = df['has_wiki'].map({'true': True, 'false': False})\n",
        "\n",
        "    correlation = df['has_projects'].corr(df['has_wiki'])\n",
        "\n",
        "    stats = {\n",
        "        'total_repos': len(df),\n",
        "        'projects_enabled': df['has_projects'].sum(),\n",
        "        'wiki_enabled': df['has_wiki'].sum(),\n",
        "        'both_enabled': ((df['has_projects']) & (df['has_wiki'])).sum(),\n",
        "        'neither_enabled': ((~df['has_projects']) & (~df['has_wiki'])).sum()\n",
        "    }\n",
        "\n",
        "    return round(correlation, 3), stats\n",
        "\n",
        "correlation, stats = analyze_repo_features('repositories.csv')\n",
        "print(f\"Correlation coefficient: {correlation}\")\n",
        "print(\"\\nAdditional Statistics:\")\n",
        "for key, value in stats.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ktb1S3GyZDnq",
        "outputId": "b2f9f84d-f7f0-43cd-c739-40b7c9f0175f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation coefficient: 0.274\n",
            "\n",
            "Additional Statistics:\n",
            "total_repos: 41129\n",
            "projects_enabled: 39682\n",
            "wiki_enabled: 35040\n",
            "both_enabled: 34545\n",
            "neither_enabled: 952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q12\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data from the CSV file\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter hireable and non-hireable users\n",
        "hireable_users = users_df[users_df['hireable'] == True]\n",
        "non_hireable_users = users_df[users_df['hireable'].isna() | (users_df['hireable'] == False)]\n",
        "\n",
        "# Calculate average following for both groups\n",
        "average_hireable_following = hireable_users['following'].mean()\n",
        "average_non_hireable_following = non_hireable_users['following'].mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = average_hireable_following - average_non_hireable_following\n",
        "\n",
        "# Print the result rounded to three decimal places\n",
        "print(f'Difference in average following (hireable - non-hireable): {difference:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzQdycN_ZGA1",
        "outputId": "dc1b66b6-3291-42b3-d13e-1ff6e8f699f3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in average following (hireable - non-hireable): 109.015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q13\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'users.csv'  # Ensure this path is correct\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Check the first few rows and the data types of the DataFrame\n",
        "print(\"DataFrame Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Filter out users without bios\n",
        "df = df[df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of each bio in words\n",
        "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the independent variable (X) and dependent variable (y)\n",
        "X = df['bio_word_count']\n",
        "y = df['followers']  # Adjust the column name as per your dataset\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of the bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the regression slope rounded to three decimal places\n",
        "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEJZBd4CZHxP",
        "outputId": "847a39a2-dbf4-4ea4-9cb2-50e2c87b4f9c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Overview:\n",
            "          login           name                       company  \\\n",
            "0        getify   Kyle Simpson              GETIFY SOLUTIONS   \n",
            "1       benawad       Ben Awad                       VOIDPET   \n",
            "2  steveklabnik  Steve Klabnik                 OXIDECOMPUTER   \n",
            "3    cloudflare     Cloudflare                           NaN   \n",
            "4       jbogard   Jimmy Bogard  JIMMY BOGARD CONSULTING, LLC   \n",
            "\n",
            "                                           location                   email  \\\n",
            "0                                        Austin, TX        getify@gmail.com   \n",
            "1                                        Austin, TX                     NaN   \n",
            "2                                        Austin, TX  steve@steveklabnik.com   \n",
            "3  San Francisco, London, Austin, Lisbon, Singapore                     NaN   \n",
            "4                                        Austin, TX  jimmy.bogard@gmail.com   \n",
            "\n",
            "   hireable                                                bio  public_repos  \\\n",
            "0      True  Kyle Simpson is a Human-Centric Technologist. ...            69   \n",
            "1     False          React.js, Typescript, Node.js, PostgreSQL           254   \n",
            "2     False  All i'm trying to do is enjoy every day to the...           832   \n",
            "3     False                                                NaN           475   \n",
            "4     False         The Barley Architect, Architect Consultant           139   \n",
            "\n",
            "   followers  following            created_at  \n",
            "0      43934          2  2009-11-08T06:56:21Z  \n",
            "1      29015          4  2014-06-12T15:55:20Z  \n",
            "2       6803        206  2008-10-06T17:40:28Z  \n",
            "3       6440          0  2010-06-25T01:24:59Z  \n",
            "4       5944          3  2009-07-13T18:05:22Z  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 476 entries, 0 to 475\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   login         476 non-null    object\n",
            " 1   name          471 non-null    object\n",
            " 2   company       286 non-null    object\n",
            " 3   location      476 non-null    object\n",
            " 4   email         237 non-null    object\n",
            " 5   hireable      476 non-null    bool  \n",
            " 6   bio           310 non-null    object\n",
            " 7   public_repos  476 non-null    int64 \n",
            " 8   followers     476 non-null    int64 \n",
            " 9   following     476 non-null    int64 \n",
            " 10  created_at    476 non-null    object\n",
            "dtypes: bool(1), int64(3), object(7)\n",
            "memory usage: 37.8+ KB\n",
            "None\n",
            "\n",
            "Regression slope of followers on bio word count: 7.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q14\n",
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data from the CSV file\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert the created_at column to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter for weekend days (Saturday: 5, Sunday: 6)\n",
        "weekend_repos = repos_df[repos_df['created_at'].dt.dayofweek.isin([5, 6])]\n",
        "\n",
        "# Count the number of repositories created by each user\n",
        "top_users = weekend_repos['login'].value_counts().head(5)\n",
        "\n",
        "# Get the top 5 users' logins in order\n",
        "top_users_logins = ', '.join(top_users.index)\n",
        "\n",
        "# Print the result\n",
        "print(f'Top 5 users who created the most repositories on weekends: {top_users_logins}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qp6pliipZKud",
        "outputId": "2bdc7ec0-0b96-4297-ee28-291ec0221a20"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends: FellowTraveler, realityexpander, OR13, PaulBratslavsky, skeptycal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q15\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data from the CSV file\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Total number of users\n",
        "total_users = len(users_df)\n",
        "\n",
        "# Filter hireable and non-hireable users\n",
        "hireable_users = users_df[users_df['hireable'] == True]\n",
        "non_hireable_users = users_df[users_df['hireable'].isna() | (users_df['hireable'] == False)]\n",
        "\n",
        "# Calculate the fraction of users with email in both groups\n",
        "fraction_hireable_with_email = hireable_users['email'].notna().mean()\n",
        "fraction_non_hireable_with_email = non_hireable_users['email'].notna().mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = fraction_hireable_with_email - fraction_non_hireable_with_email\n",
        "\n",
        "# Print the result rounded to three decimal places\n",
        "print(f'Difference in fraction of users with email: {difference:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LD3YmUanZMmH",
        "outputId": "dae036af-e133-47f9-e099-5644da3cf585"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in fraction of users with email: 0.022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q16\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data from the CSV file\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter out users without names\n",
        "valid_users = users_df[users_df['name'].notna()]\n",
        "\n",
        "# Extract surnames (last word in name)\n",
        "valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = valid_users['surname'].value_counts()\n",
        "\n",
        "# Find the most common surname(s)\n",
        "max_count = surname_counts.max()\n",
        "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
        "\n",
        "# Sort surnames alphabetically\n",
        "most_common_surnames.sort()\n",
        "\n",
        "# Count users with the most common surname\n",
        "number_of_users = max_count\n",
        "\n",
        "# Print results\n",
        "most_common_surnames_str = ', '.join(most_common_surnames)\n",
        "print(f'Most common surname(s): {most_common_surnames_str}')\n",
        "print(f'Number of users with the most common surname: {number_of_users}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMncGwRSZOxQ",
        "outputId": "9304c997-ee6c-4d42-9983-ffa94852b993"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common surname(s): Labs, Moore, Smith\n",
            "Number of users with the most common surname: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-dc0f22873520>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "repositories_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Check the data types and structure\n",
        "print(repositories_df.head())\n",
        "\n",
        "# Replace True/False with true/false\n",
        "repositories_df['has_projects'] = repositories_df['has_projects'].replace({True: 'true', False: 'false'})\n",
        "repositories_df['has_wiki'] = repositories_df['has_wiki'].replace({True: 'true', False: 'false'})\n",
        "\n",
        "# Save the modified DataFrame back to the same CSV file\n",
        "repositories_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "# Check the data types and structure\n",
        "print(repositories_df.head())\n",
        "\n",
        "print(\"Updated CSV file saved successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhdL-TFiZQe2",
        "outputId": "722fb20e-eb84-4799-98f7-7b692acaa0fe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    login                    full_name            created_at  \\\n",
            "0  getify           getify/sweetalert2  2024-09-05T02:19:43Z   \n",
            "1  getify              getify/foi-lang  2022-09-22T15:59:56Z   \n",
            "2  getify      getify/You-Dont-Know-JS  2013-11-16T02:37:24Z   \n",
            "3  getify  getify/demo-app-weatheround  2023-10-04T15:21:53Z   \n",
            "4  getify          getify/import-remap  2021-01-21T21:43:48Z   \n",
            "\n",
            "   stargazers_count  watchers_count    language  has_projects  has_wiki  \\\n",
            "0                 1               1         NaN          True      True   \n",
            "1               308             308  JavaScript          True      True   \n",
            "2            179606          179606         NaN          True     False   \n",
            "3                 7               7  JavaScript          True      True   \n",
            "4                25              25  JavaScript          True      True   \n",
            "\n",
            "  license_name  \n",
            "0          mit  \n",
            "1          mit  \n",
            "2        other  \n",
            "3          mit  \n",
            "4          mit  \n",
            "    login                    full_name            created_at  \\\n",
            "0  getify           getify/sweetalert2  2024-09-05T02:19:43Z   \n",
            "1  getify              getify/foi-lang  2022-09-22T15:59:56Z   \n",
            "2  getify      getify/You-Dont-Know-JS  2013-11-16T02:37:24Z   \n",
            "3  getify  getify/demo-app-weatheround  2023-10-04T15:21:53Z   \n",
            "4  getify          getify/import-remap  2021-01-21T21:43:48Z   \n",
            "\n",
            "   stargazers_count  watchers_count    language has_projects has_wiki  \\\n",
            "0                 1               1         NaN         true     true   \n",
            "1               308             308  JavaScript         true     true   \n",
            "2            179606          179606         NaN         true    false   \n",
            "3                 7               7  JavaScript         true     true   \n",
            "4                25              25  JavaScript         true     true   \n",
            "\n",
            "  license_name  \n",
            "0          mit  \n",
            "1          mit  \n",
            "2        other  \n",
            "3          mit  \n",
            "4          mit  \n",
            "Updated CSV file saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Check the data types and structure\n",
        "print(users_df.head())\n",
        "\n",
        "# Replace True/False with true/false in the hireable column\n",
        "users_df['hireable'] = users_df['hireable'].replace({True: 'true', False: 'false'})\n",
        "\n",
        "# Save the modified DataFrame back to the same CSV file\n",
        "users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "# Check the data types and structure\n",
        "print(users_df.head())\n",
        "\n",
        "\n",
        "print(\"Updated CSV file saved successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr1ktofbcLk-",
        "outputId": "d0bad58a-fefa-4fc7-b84f-17a9559fe5f1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          login           name                       company  \\\n",
            "0        getify   Kyle Simpson              GETIFY SOLUTIONS   \n",
            "1       benawad       Ben Awad                       VOIDPET   \n",
            "2  steveklabnik  Steve Klabnik                 OXIDECOMPUTER   \n",
            "3    cloudflare     Cloudflare                           NaN   \n",
            "4       jbogard   Jimmy Bogard  JIMMY BOGARD CONSULTING, LLC   \n",
            "\n",
            "                                           location                   email  \\\n",
            "0                                        Austin, TX        getify@gmail.com   \n",
            "1                                        Austin, TX                     NaN   \n",
            "2                                        Austin, TX  steve@steveklabnik.com   \n",
            "3  San Francisco, London, Austin, Lisbon, Singapore                     NaN   \n",
            "4                                        Austin, TX  jimmy.bogard@gmail.com   \n",
            "\n",
            "  hireable                                                bio  public_repos  \\\n",
            "0     True  Kyle Simpson is a Human-Centric Technologist. ...            69   \n",
            "1      NaN          React.js, Typescript, Node.js, PostgreSQL           254   \n",
            "2      NaN  All i'm trying to do is enjoy every day to the...           832   \n",
            "3      NaN                                                NaN           475   \n",
            "4      NaN         The Barley Architect, Architect Consultant           139   \n",
            "\n",
            "   followers  following            created_at  \n",
            "0      43934          2  2009-11-08T06:56:21Z  \n",
            "1      29015          4  2014-06-12T15:55:20Z  \n",
            "2       6803        206  2008-10-06T17:40:28Z  \n",
            "3       6440          0  2010-06-25T01:24:59Z  \n",
            "4       5944          3  2009-07-13T18:05:22Z  \n",
            "          login           name                       company  \\\n",
            "0        getify   Kyle Simpson              GETIFY SOLUTIONS   \n",
            "1       benawad       Ben Awad                       VOIDPET   \n",
            "2  steveklabnik  Steve Klabnik                 OXIDECOMPUTER   \n",
            "3    cloudflare     Cloudflare                           NaN   \n",
            "4       jbogard   Jimmy Bogard  JIMMY BOGARD CONSULTING, LLC   \n",
            "\n",
            "                                           location                   email  \\\n",
            "0                                        Austin, TX        getify@gmail.com   \n",
            "1                                        Austin, TX                     NaN   \n",
            "2                                        Austin, TX  steve@steveklabnik.com   \n",
            "3  San Francisco, London, Austin, Lisbon, Singapore                     NaN   \n",
            "4                                        Austin, TX  jimmy.bogard@gmail.com   \n",
            "\n",
            "  hireable                                                bio  public_repos  \\\n",
            "0     true  Kyle Simpson is a Human-Centric Technologist. ...            69   \n",
            "1      NaN          React.js, Typescript, Node.js, PostgreSQL           254   \n",
            "2      NaN  All i'm trying to do is enjoy every day to the...           832   \n",
            "3      NaN                                                NaN           475   \n",
            "4      NaN         The Barley Architect, Architect Consultant           139   \n",
            "\n",
            "   followers  following            created_at  \n",
            "0      43934          2  2009-11-08T06:56:21Z  \n",
            "1      29015          4  2014-06-12T15:55:20Z  \n",
            "2       6803        206  2008-10-06T17:40:28Z  \n",
            "3       6440          0  2010-06-25T01:24:59Z  \n",
            "4       5944          3  2009-07-13T18:05:22Z  \n",
            "Updated CSV file saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q16\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data from the CSV file\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Filter out users without names\n",
        "valid_users = users_df[users_df['name'].notna()]\n",
        "\n",
        "# Extract surnames (last word in name)\n",
        "valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n",
        "\n",
        "# Count occurrences of each surname\n",
        "surname_counts = valid_users['surname'].value_counts()\n",
        "\n",
        "# Find the most common surname(s)\n",
        "max_count = surname_counts.max()\n",
        "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
        "\n",
        "# Sort surnames alphabetically\n",
        "most_common_surnames.sort()\n",
        "\n",
        "# Count users with the most common surname\n",
        "number_of_users = max_count\n",
        "\n",
        "# Print results\n",
        "most_common_surnames_str = ', '.join(most_common_surnames)\n",
        "print(f'Most common surname(s): {most_common_surnames_str}')\n",
        "print(f'Number of users with the most common surname: {number_of_users}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cKPGlJCFKYE",
        "outputId": "953beaed-da2e-454e-f6e5-c6c5b1a95efd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most common surname(s): Labs, Moore, Smith\n",
            "Number of users with the most common surname: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-dc0f22873520>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  valid_users['surname'] = valid_users['name'].str.strip().str.split().str[-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'users.csv'  # Ensure this path is correct\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Check the first few rows and the data types of the DataFrame\n",
        "print(\"DataFrame Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Filter out users without bios\n",
        "df = df[df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of each bio in words\n",
        "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the independent variable (X) and dependent variable (y)\n",
        "X = df['bio_word_count']\n",
        "y = df['followers']  # Adjust the column name as per your dataset\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of the bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the regression slope rounded to three decimal places\n",
        "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "843bVbu7GBN4",
        "outputId": "aa92d78c-f9e3-4748-c2d1-88fa4704653a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Overview:\n",
            "          login           name                       company  \\\n",
            "0        getify   Kyle Simpson              GETIFY SOLUTIONS   \n",
            "1       benawad       Ben Awad                       VOIDPET   \n",
            "2  steveklabnik  Steve Klabnik                 OXIDECOMPUTER   \n",
            "3    cloudflare     Cloudflare                           NaN   \n",
            "4       jbogard   Jimmy Bogard  JIMMY BOGARD CONSULTING, LLC   \n",
            "\n",
            "                                           location                   email  \\\n",
            "0                                        Austin, TX        getify@gmail.com   \n",
            "1                                        Austin, TX                     NaN   \n",
            "2                                        Austin, TX  steve@steveklabnik.com   \n",
            "3  San Francisco, London, Austin, Lisbon, Singapore                     NaN   \n",
            "4                                        Austin, TX  jimmy.bogard@gmail.com   \n",
            "\n",
            "   hireable                                                bio  public_repos  \\\n",
            "0      True  Kyle Simpson is a Human-Centric Technologist. ...            69   \n",
            "1     False          React.js, Typescript, Node.js, PostgreSQL           254   \n",
            "2     False  All i'm trying to do is enjoy every day to the...           832   \n",
            "3     False                                                NaN           475   \n",
            "4     False         The Barley Architect, Architect Consultant           139   \n",
            "\n",
            "   followers  following            created_at  \n",
            "0      43934          2  2009-11-08T06:56:21Z  \n",
            "1      29015          4  2014-06-12T15:55:20Z  \n",
            "2       6803        206  2008-10-06T17:40:28Z  \n",
            "3       6440          0  2010-06-25T01:24:59Z  \n",
            "4       5944          3  2009-07-13T18:05:22Z  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 476 entries, 0 to 475\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   login         476 non-null    object\n",
            " 1   name          471 non-null    object\n",
            " 2   company       286 non-null    object\n",
            " 3   location      476 non-null    object\n",
            " 4   email         237 non-null    object\n",
            " 5   hireable      476 non-null    bool  \n",
            " 6   bio           310 non-null    object\n",
            " 7   public_repos  476 non-null    int64 \n",
            " 8   followers     476 non-null    int64 \n",
            " 9   following     476 non-null    int64 \n",
            " 10  created_at    476 non-null    object\n",
            "dtypes: bool(1), int64(3), object(7)\n",
            "memory usage: 37.8+ KB\n",
            "None\n",
            "\n",
            "Regression slope of followers on bio word count: 7.795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-2d0cbe58dc40>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['bio_word_count'] = df['bio'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Filter out rows where 'bio' is NaN (i.e., users without a bio)\n",
        "users_df = pd.read_csv('users.csv')\n",
        "users_with_bio = users_df[users_df['bio'].notna()]\n",
        "\n",
        "# Calculate word count for each bio\n",
        "users_with_bio['bio_word_count'] = users_with_bio['bio'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Extract bio word counts and followers as separate arrays for regression\n",
        "X = users_with_bio[['bio_word_count']]\n",
        "y = users_with_bio['followers']\n",
        "\n",
        "# Perform linear regression to get the slope\n",
        "regression_model = LinearRegression().fit(X, y)\n",
        "slope = regression_model.coef_[0]  # Get the slope of followers with respect to bio word count\n",
        "\n",
        "print(slope)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5y-Oqz4QsT-",
        "outputId": "b8f28f1f-e6e9-45d8-d70c-1df471f8e91f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.795229339103146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-8c25bfd2774c>:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bio['bio_word_count'] = users_with_bio['bio'].apply(lambda x: len(x.split()))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'users.csv'  # Ensure this path is correct\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Check the first few rows and the data types of the DataFrame\n",
        "print(\"DataFrame Overview:\")\n",
        "print(df.head())\n",
        "print(\"\\nDataFrame Info:\")\n",
        "print(df.info())\n",
        "\n",
        "# Filter out users without bios\n",
        "df = df[df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of each bio in words\n",
        "df['bio_word_count'] = df['bio'].str.split().str.len()\n",
        "\n",
        "# Prepare the independent variable (X) and dependent variable (y)\n",
        "X = df['bio_word_count']\n",
        "y = df['followers']  # Adjust the column name as per your dataset\n",
        "\n",
        "# Add a constant to the independent variable (for the intercept)\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of the bio_word_count)\n",
        "slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the regression slope rounded to three decimal places\n",
        "print(f\"\\nRegression slope of followers on bio word count: {slope:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKgxcKzvmaL4",
        "outputId": "d0ca8947-fdf1-4a1e-d705-82870e9f8193"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame Overview:\n",
            "          login           name                       company  \\\n",
            "0        getify   Kyle Simpson              GETIFY SOLUTIONS   \n",
            "1       benawad       Ben Awad                       VOIDPET   \n",
            "2  steveklabnik  Steve Klabnik                 OXIDECOMPUTER   \n",
            "3    cloudflare     Cloudflare                           NaN   \n",
            "4       jbogard   Jimmy Bogard  JIMMY BOGARD CONSULTING, LLC   \n",
            "\n",
            "                                           location                   email  \\\n",
            "0                                        Austin, TX        getify@gmail.com   \n",
            "1                                        Austin, TX                     NaN   \n",
            "2                                        Austin, TX  steve@steveklabnik.com   \n",
            "3  San Francisco, London, Austin, Lisbon, Singapore                     NaN   \n",
            "4                                        Austin, TX  jimmy.bogard@gmail.com   \n",
            "\n",
            "   hireable                                                bio  public_repos  \\\n",
            "0      True  Kyle Simpson is a Human-Centric Technologist. ...            69   \n",
            "1     False          React.js, Typescript, Node.js, PostgreSQL           254   \n",
            "2     False  All i'm trying to do is enjoy every day to the...           832   \n",
            "3     False                                                NaN           475   \n",
            "4     False         The Barley Architect, Architect Consultant           139   \n",
            "\n",
            "   followers  following            created_at  \n",
            "0      43934          2  2009-11-08T06:56:21Z  \n",
            "1      29015          4  2014-06-12T15:55:20Z  \n",
            "2       6803        206  2008-10-06T17:40:28Z  \n",
            "3       6440          0  2010-06-25T01:24:59Z  \n",
            "4       5944          3  2009-07-13T18:05:22Z  \n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 476 entries, 0 to 475\n",
            "Data columns (total 11 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   login         476 non-null    object\n",
            " 1   name          471 non-null    object\n",
            " 2   company       286 non-null    object\n",
            " 3   location      476 non-null    object\n",
            " 4   email         237 non-null    object\n",
            " 5   hireable      476 non-null    bool  \n",
            " 6   bio           310 non-null    object\n",
            " 7   public_repos  476 non-null    int64 \n",
            " 8   followers     476 non-null    int64 \n",
            " 9   following     476 non-null    int64 \n",
            " 10  created_at    476 non-null    object\n",
            "dtypes: bool(1), int64(3), object(7)\n",
            "memory usage: 37.8+ KB\n",
            "None\n",
            "\n",
            "Regression slope of followers on bio word count: 7.795\n"
          ]
        }
      ]
    }
  ]
}